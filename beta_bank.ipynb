{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Clientes do Beta Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Determinar o motivo pelo qual os clientes estão saindo da instituição aos poucos todo mês. Para a empresa, manter os clientes ativos é mais barato do que prospectar novos clientes. Precisamos prever se um cliente vai deixar o banco em breve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFreme\n",
    "\n",
    "df = pd.read_csv('Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examinando os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "\n",
      "RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Indetificando os dados\n",
    "print(df.info())\n",
    "print()\n",
    "print(df.head())\n",
    "print()\n",
    "print(df.isnull().sum()) # Verifica se há valores ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Após examinar os dados, não foi encontrado dados discrepantes nem em seu formato, apenas a coluna \"Tenure\" que está no formato float, mas após examinar os dados (por ano) podemos concluir que pode estar em formato inteiro. Em relação aos numeros ausentes, a coluna \"Tenure\" tem 909 numeros ausentes. Como isso se refere ao anos de cada cliente com conta, posso concluir que os numeros ausentes são clientes que não completaram 1 ano de conta com o banco. Vou alterar para 0 e definir que esse valor é para clientes que não completaram 1 ano na instituíção.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int32  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int32(1), int64(8), object(3)\n",
      "memory usage: 1.0+ MB\n",
      "None\n",
      "RowNumber          0\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Transformando coluna para Int e valores ausente para 0\n",
    "\n",
    "df['Tenure'] = df['Tenure'].fillna(0).astype(int)\n",
    "\n",
    "# Verificando as modificações:\n",
    "\n",
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
      "0          619    France  Female   42       2       0.00              1   \n",
      "1          608     Spain  Female   41       1   83807.86              1   \n",
      "2          502    France  Female   42       8  159660.80              3   \n",
      "3          699    France  Female   39       1       0.00              2   \n",
      "4          850     Spain  Female   43       2  125510.82              1   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
      "0          1               1        101348.88       1  \n",
      "1          0               1        112542.58       0  \n",
      "2          1               0        113931.57       1  \n",
      "3          0               0         93826.63       0  \n",
      "4          1               1         79084.10       0  \n"
     ]
    }
   ],
   "source": [
    "# Removendo colunas irrelevantes\n",
    "df = df.drop(columns=['RowNumber', 'CustomerId', 'Surname'])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As colunas RowNumber, CustomerId e Surname não contribuem para a previsão do churn (saída do cliente), por isso elas foram removidas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação de variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding para Geography\n",
    "df = pd.get_dummies(df, columns=['Geography'], drop_first=True)\n",
    "\n",
    "# Label Encoding para Gender\n",
    "df['Gender'] = df['Gender'].map({'Female': 0, 'Male': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As colunas 'Geography' e 'Gender' são variáveis categóricas e precisam ser convertidas para um formato numérico.**\n",
    "\n",
    "- Para Geography, podemos usar One-Hot Encoding porque há mais de duas categorias (exemplo: França, Espanha, Alemanha);\n",
    "- Para Gender, podemos usar Label Encoding (0 para Female e 1 para Male);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "0          619       0   42       2       0.00              1          1   \n",
      "1          608       0   41       1   83807.86              1          0   \n",
      "2          502       0   42       8  159660.80              3          1   \n",
      "3          699       0   39       1       0.00              2          0   \n",
      "4          850       0   43       2  125510.82              1          1   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  Geography_Spain  \n",
      "0               1        101348.88       1              False            False  \n",
      "1               1        112542.58       0              False             True  \n",
      "2               0        113931.57       1              False            False  \n",
      "3               0         93826.63       0              False            False  \n",
      "4               1         79084.10       0              False             True  \n"
     ]
    }
   ],
   "source": [
    "# Verificando as alterações\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realizei a padronização dos dados numéricos de um DataFrame utilizando a classe 'StandardScaler' da biblioteca 'scikit-learn'.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão dos Dados em Conjunto de Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Definindo as features (X) e o target (y)\n",
    "X = df.drop(columns=['Exited'])  # Removendo a coluna alvo\n",
    "y = df['Exited']  # Definindo a variável alvo\n",
    "\n",
    "# Dividindo os dados em 80% treino e 20% teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Antes de treinar o modelo, dividi os dados em treino e teste para avaliar o desempenho de maneira realista. Separei 80% dos dados para treino e 20% para teste.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando o Equilíbrio das Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thiago\\AppData\\Local\\Temp\\ipykernel_12756\\1458244585.py:6: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=class_counts.index, y=class_counts.values, palette=['blue', 'red'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAGKCAYAAADTzzFNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWcklEQVR4nO3deVhU5fs/8PcAMmzOIAgMJAKKKbhv6aipJYqGmqm5K+5pmCG58UlxybIo10yt/KSWkltuiRvhQim5YCgu4IZi4oCKMKKyCM/vj36cryOggOCcT7xf13Wui3me+zznPjAwN8+c84xCCCFAREREZGQmxk6AiIiICGBRQkRERDLBooSIiIhkgUUJERERyQKLEiIiIpIFFiVEREQkCyxKiIiISBZYlBAREZEssCghokrrzp07mDNnDo4fP27sVIgILEpIxmbPng2FQvFSjtWxY0d07NhRenzo0CEoFAps2bKl3I5x7do1KBQKrFmzptT7btmyBba2tmjbti0uXbqEsWPHYvHixeWW27MoFArMnj37pRyrvLm7u2P48OFF9gkh4O/vj8OHD6NJkyYVnktFfB+fft6+TJmZmXB0dMT69esr7BgFv4eHDh2qsGM86emf0cqVK1GzZk1kZ2e/lOMTixJ6SdasWQOFQiFtFhYWcHFxga+vL5YuXYr79++Xy3GSk5Mxe/ZsxMbGlst4chEaGoqxY8fC2dkZ9erVw9atW9GrVy9jp1UqW7duhUKhwKpVq4qNiYiIgEKhwNKlSys8n6+++grXr1/Htm3bYG5uXuHHK60LFy5Ivyvp6enGTqeQJUuWoGrVqhgwYIDUVvCPRHGbTqd74eOGhYW9tIJ8+PDhyMnJwbfffvtSjkeAmbEToMpl7ty58PDwQG5uLnQ6HQ4dOoTAwEAsXLgQO3fuRKNGjaTYGTNmYPr06aUaPzk5GXPmzIG7u3up/vvdv39/qY5TFm5ubnj06BGqVKlS6n03b96MV155BWZmZrh9+zaqVq0KCwuLCsiy4vj5+UGtViMsLAyjR48uMiYsLAympqYGL3QvIiEhASYmhf/3ys7ORk5ODnbv3g21Wl0uxypv69atg0ajwb1797Bly5Ziv2fGkJubiyVLlmDSpEkwNTUt1L9ixQrY2NgUare1tS3Vcdq3b49Hjx4ZFI1hYWE4e/YsAgMDS5t2qVlYWMDf3x8LFy7EBx988NJmbiszFiX0UnXr1g0tWrSQHgcHB+PAgQPo3r07evbsiQsXLsDS0hIAYGZmBjOzin2KPnz4EFZWVi/lP+WC/3rLws3NTfrawcGhvFJ6qZRKJfr27YvVq1cjOTkZLi4uBv1ZWVnYtm0bOnfuDEdHxzIfRwiBrKwsWFpaQqlUFpvLxx9/XOZjVDQhBMLCwjBo0CAkJiZi/fr1sipKdu3ahdu3b6Nfv35F9vft2xfVq1d/4eOYmJgYvfju168fQkNDcfDgQbz55ptGzaUy4Ns3ZHRvvvkmZs6cievXr2PdunVSe1HXlERERKBdu3awtbWFjY0N6tati//85z8A/nn/uWXLlgCAESNGSFPGBddwdOzYEQ0aNEBMTAzat28PKysrad/i3pvPy8vDf/7zH2g0GlhbW6Nnz564ceOGQUxx1y08PWZx15TEx8ejX79+cHBwgKWlJerWrWvwgpmYmIjx48fj1VdfhaWlJezt7fHuu+/i2rVrhY559epVvPvuu7Czs4OVlRVat26N8PDwQnFFyc7OxqRJk+Dg4ICqVauiZ8+e+PvvvwvFXb9+He+//z7q1q373HyeNmTIEOTn52PDhg2F+sLDw5GRkYHBgwcDAFavXo0333wTjo6OUCqV8Pb2xooVKwrt5+7uju7du2Pfvn1o0aIFLC0tpen2p382aWlpmDx5Mho2bAgbGxuoVCp069YNp0+flmJSUlJgZmaGOXPmFDpWQkICFAoFli1bJrWlp6cjMDAQrq6uUCqV8PT0xBdffIH8/Pznfj+Kc+TIEVy7dg0DBgzAgAEDEBUVVeTP4kmlzftFnivbt2+Hu7s7ateuXboT+//8/f1hYWGBCxcuGLT7+vqiWrVqSE5OBlD4mpKOHTsiPDwc169fl36/3d3dpf2zs7Mxa9YseHp6QqlUwtXVFVOnTi10TUhJn+sA0Lx5c9jZ2WHHjh1lOlcqHc6UkCwMHToU//nPf7B//36MGTOmyJhz586he/fuaNSoEebOnQulUonLly/jyJEjAAAvLy/MnTsXISEhGDt2LF5//XUAQJs2baQx7t69i27dumHAgAEYMmQInJycnpnXp59+CoVCgWnTpiE1NRWLFy+Gj48PYmNjpRmdF3HmzBm8/vrrqFKlCsaOHQt3d3dcuXIFv/76Kz799FMAwLFjxxAdHY2BAweiRo0aSExMxMqVK9GxY0ecP38eVlZWAP55UWrTpg0ePnyIiRMnwt7eHmvXrkXPnj2xZcsWvPPOO8/MZfTo0Vi3bh0GDRqENm3a4MCBA/Dz8ysUd+LECRw9ehQDBgxAjRo1cO3aNaxYsaJQPkVp3749atSogbCwMAQFBRn0hYWFwcrKSrpWZsWKFahfvz569uwJMzMz/Prrr3j//feRn5+PgIAAg30TEhIwcOBAvPfeexgzZgzq1q1b5PGvXr2Kbdu2oV+/fvDw8EBKSgpWrFiBDh064Pz583BxcYGTkxM6dOiATZs2YdasWQb7b9y4Eaampnj33XcB/DPT1qFDB9y8eRPvvfceatasiaNHjyI4OBi3bt0q87UP69evR+3atdGyZUs0aNAAVlZW+PnnnzFlypRi9ylN3i/6XDl69CiaNWtWbH9aWlqhNjMzM+ntmyVLluDAgQPw9/dHdHQ0TE1N8e2332L//v346aefCs2iFfj444+RkZGBv//+G4sWLQIA6W2i/Px89OzZE3/88QfGjh0LLy8vxMXFYdGiRbh48SK2b98ujVPS53qBZs2aSX9nqIIJopdg9erVAoA4ceJEsTFqtVo0bdpUejxr1izx5FN00aJFAoC4fft2sWOcOHFCABCrV68u1NehQwcBQKxcubLIvg4dOkiPDx48KACIV155Rej1eql906ZNAoBYsmSJ1Obm5ib8/f2fO2ZiYmKh3Nq3by+qVq0qrl+/brBvfn6+9PXDhw8LjR0dHS0AiB9//FFqCwwMFADE77//LrXdv39feHh4CHd3d5GXl1donAKxsbECgHj//fcN2gcNGiQAiFmzZpU6n+JMmTJFABAJCQlSW0ZGhrCwsBADBw585nF8fX1FrVq1DNrc3NwEALF3795C8U//bB49eiQeP35sEHPlyhWhVCrF3LlzpbZvv/1WABBxcXEGsd7e3uLNN9+UHn/yySfC2tpaXLx40SBu+vTpwtTUVCQlJUltT38fi5OTkyPs7e3Fxx9/LLUNGjRING7cuFDs08+xkub9Is+V3NxcoVAoxEcffVSor+B3tqitbt26BrH79u0TAMS8efPE1atXhY2NjejVq5dBTMHv4cGDB6U2Pz8/4ebmVujYP/30kzAxMTE4JyGEWLlypQAgjhw5IoQo3XO9wNixY4WlpWWx3xMqP3z7hmTDxsbmmXfhFPyXtWPHjjJPjSuVSowYMaLE8cOGDUPVqlWlx3379oWzszN2795dpuM/6fbt24iKisLIkSNRs2ZNg74n37Z6ckYmNzcXd+/ehaenJ2xtbXHq1Cmpb/fu3XjttdfQrl07qc3GxgZjx47FtWvXcP78+WJzKTifiRMnGrQXdTFhSfMpzpAhQwD8MzNS4JdffkFWVpb01s3Tx8nIyMCdO3fQoUMHXL16FRkZGQZjenh4wNfX97nHtrCwMLgwMzs7Gy4uLvDy8jLIvXfv3jAzM8PGjRultrNnz+L8+fPo37+/1LZ582a8/vrrqFatGu7cuSNtPj4+yMvLQ1RU1HNzetqePXtw9+5dDBw4UGobOHAgTp8+jXPnzj1z35Lm/SLPlbS0NAghUK1atWJjfvnlF0RERBhsq1evNojp0qUL3nvvPcydOxe9e/eGhYXFC93lsnnzZnh5eaFevXoGP4uC60AOHjwonTtQsud6gWrVquHRo0d4+PBhmfOjkmFRQrKRmZlpUAA8rX///mjbti1Gjx4NJycnDBgwAJs2bSpVgfLKK6+U6qLWOnXqGDxWKBTw9PQs0fUTz3P16lUAQIMGDZ4Z9+jRI4SEhEjXLFSvXh0ODg5IT083eHG+fv16kW9beHl5Sf3FuX79OkxMTApdI1DUeCXNpziNGjVCgwYN8PPPP0ttYWFhqF69ukFhceTIEfj4+MDa2hq2trZwcHCQrgEqqigpCSEEVq5ciSZNmsDGxgYWFhawtLREbGyswZjVq1dHp06dsGnTJqlt48aNMDMzQ+/evaW2S5cuYe/evXBwcDDYfHx8AACpqaklyutJ69atg4eHh/T25OXLl1G7dm1YWVk9d02Qkub9Is+VAkKIYvvat28PHx8fg02r1RaK++qrr2BnZ4fY2FgsXbr0hS5wvnTpEs6dO1foZ/Hqq68C+L+fRWme6wUKzpV331Q8XlNCsvD3338jIyMDnp6excZYWloiKioKBw8eRHh4OPbu3YuNGzfizTffxP79+4u8NbGoMcpbcX+o8vLySpTT83zwwQdYvXo1AgMDodVqoVaroVAoMGDAgBe6mNKY+QwZMgTTp0/HyZMnUaNGDRw8eBDvvfeedLfVlStX0KlTJ9SrVw8LFy6Eq6srzM3NsXv3bixatKjQcUr6c/3iiy8QHByMgIAAfPLJJ7C3t4eJiQnGjh1baMwBAwZgxIgRiI2NRZMmTbBp0yZ06tTJ4K6S/Px8dO7cGVOnTi3yeAUviCWl1+vx66+/Iisrq1BBDPxTvBVc51SckuT9Iuzs7KBQKHDv3r0XHuuvv/6SioW4uDiD2aHSys/PR8OGDbFw4cIi+11dXcs89r1792BlZVUhfz/IEIsSkoWffvoJAJ47BW9iYoJOnTqhU6dOWLhwIT777DN8/PHHOHjwIHx8fMr9P5lLly4ZPBZC4PLlywbrqVSrVq3Ixa2uX7+OWrVqFTt2Qd/Zs2efmcOWLVvg7++PBQsWSG1ZWVmFjunm5oaEhIRC+8fHx0v9xXFzc0N+fj6uXLli8B9jUeOVNJ9nGThwIIKDgxEWFgY3Nzfk5eUZvHXz66+/Ijs7Gzt37jR4a6tgCr6sNm7cCB8fH4O7UIB/lpu3s7MzaOvVqxfee+896a2QixcvIjg42CCmdu3ayMzMlGZGXtTWrVuRlZWFFStWFCoiEhISMGPGDBw5csTgbZenlSTvF3mumJmZoXbt2khMTCzxeRXlwYMHGDFiBLy9vdGmTRuEhobinXfeke6gK05xv+O1a9fG6dOn0alTp2f+HSjNc71AYmKiNItEFYtv35DRHThwAJ988gk8PDwMXpieVtQV/QULpBXc8mdtbQ0A5bYC5o8//mhwncuWLVtw69YtdOvWTWqrXbs2/vzzT+Tk5Ehtu3btKnTr8NMcHBzQvn17/PDDD0hKSjLoe3Jq3NTUtNBU+ddff428vDyDtrfeegvHjx9HdHS01PbgwQN89913cHd3h7e3d7G5FJzP0yupFnX3SEnzeZaaNWvi9ddfx8aNG6W3K568S6pghunJ42RkZBS6LqG0FAoFcnNzDdp+/vln3Lp1q1Csra0tfH19sWnTJmzYsAHm5uaFVtHt168foqOjsW/fvkL7p6en4/Hjx6XKb926dahVqxbGjRuHvn37GmyTJ0+GjY3Nc9/CKUneL/JcAQCtVouTJ0+W6tyeNm3aNCQlJWHt2rVYuHAh3N3d4e/v/9wl3a2trYt8m7Bfv364efMmvv/++0J9jx49woMHDwCU7rle4NSpUwbPT6o4nCmhl2rPnj2Ij4/H48ePkZKSggMHDiAiIgJubm7YuXPnMxdKmjt3LqKiouDn5wc3NzekpqZi+fLlqFGjhvSfY+3atWFra4uVK1eiatWqsLa2RqtWrUp8zcHT7Ozs0K5dO4wYMQIpKSlYvHgxPD09DW5bHj16NLZs2YKuXbuiX79+uHLlCtatW1eiNRyWLl2Kdu3aoVmzZhg7diw8PDxw7do1hIeHS0vld+/eHT/99BPUajW8vb0RHR2N3377Dfb29gZjTZ8+HT///DO6deuGiRMnws7ODmvXrkViYiJ++eWXIlc2LdCkSRMMHDgQy5cvR0ZGBtq0aYPIyEhcvny5UGxJ83meIUOGYOzYsUhOTi60kFmXLl1gbm6OHj164L333kNmZia+//57ODo6FllAlJSfnx/mzZuHESNGQKvVIi4uDmFhYcX+rPr3748hQ4Zg+fLl8PX1LbQi6ZQpU7Bz5050794dw4cPR/PmzfHgwQPExcVhy5YtuHbtWonfNklOTsbBgwcLXYBZQKlUwtfXF5s3b8bSpUufuTLw8/J+kecKALz99tv46aefcPHixSLfotqyZUuRK7p27twZTk5OOHDgAJYvX45Zs2ZJtxavXr0aHTt2xMyZMxEaGlrssZs3b46NGzciKCgILVu2hI2NDXr06IGhQ4di06ZNGDduHA4ePIi2bdsiLy8P8fHx2LRpk7SOTWme6wAQExODtLQ0vP3228/8nlA5Mdp9P1SpFNwSXLCZm5sLjUYjOnfuLJYsWWJw222Bp28JjoyMFG+//bZwcXER5ubmwsXFRQwcOLDQ7Zg7duwQ3t7ewszMzOAW3A4dOoj69esXmV9xtwT//PPPIjg4WDg6OgpLS0vh5+dX6PZdIYRYsGCBeOWVV4RSqRRt27YVJ0+eLNEtwUIIcfbsWfHOO+8IlUol3To5c+ZMqf/evXtixIgRonr16sLGxkb4+vqK+Pj4Im9FvnLliujbt6+wtbUVFhYW4rXXXhO7du0q8pyf9ujRIzFx4kRhb28vrK2tRY8ePcSNGzcK3SZZmnyeJS0tTSiVSgFAnD9/vlD/zp07RaNGjYSFhYVwd3cXX3zxhfjhhx8EAJGYmCjFubm5CT8/vyKP8XROWVlZIjAwUDg7OwsrKyvx+uuvi+PHjxf6WRXQ6/XC0tJSABDr1q0r8hj3798XwcHBwtPTU5ibm4vq1auLNm3aiK+++krk5ORIcU9/H5+2YMECAUBERkYWG7NmzRoBQOzYsUMIUfh5W5q8X+S5kp2dLapXry4++eQTg/Zn3RKM/39rr16vF25ubqJZs2YiNzfXYP9JkyYJExMTER0dLYQo+pbgzMxMMWjQIGFraysAGNwenJOTI7744gtRv359oVQqRbVq1UTz5s3FnDlzREZGhhRX0ue6EEJMmzZN1KxZ0+A2fao4CiGecQk1Eb1UPj4+mDp1Krp06WLsVIie6ZNPPsHq1atx6dKlcrmgW46ys7Ph7u6O6dOn48MPPzR2OpUCrykhkpEePXoYLLVPJFeTJk1CZmZmkR8Z8G+xevVqVKlSBePGjTN2KpUGZ0qIZODnn3/GgwcPsGbNGjg6OmLr1q3GTomI6KXjTAmRDJw7dw4TJkzAzZs3MXnyZGOnQ0RkFJwpISIiIlngTAkRERHJAosSIiIikgUWJURERCQLXNG1BPLz85GcnIyqVavyUyKJiIhKQQiB+/fvw8XF5bmrBbMoKYHk5OQX+oRJIiKiyu7GjRuoUaPGM2NYlJRA1apVAfzzDVWpVEbOhoiI6H+HXq+Hq6ur9Fr6LCxKSqDgLRuVSsWihIiIqAxKcvkDL3QlIiIiWWBRQkRERLLAooSIiIhkgUUJERERyQKLEiIiIpIFFiVEREQkC0YtSvLy8jBz5kx4eHjA0tIStWvXxieffIInP7hYCIGQkBA4OzvD0tISPj4+uHTpksE4aWlpGDx4MFQqFWxtbTFq1ChkZmYaxJw5cwavv/46LCws4OrqitDQ0JdyjkRERFQyRi1KvvjiC6xYsQLLli3DhQsX8MUXXyA0NBRff/21FBMaGoqlS5di5cqVOHbsGKytreHr64usrCwpZvDgwTh37hwiIiKwa9cuREVFYezYsVK/Xq9Hly5d4ObmhpiYGHz55ZeYPXs2vvvuu5d6vkRERPQMwoj8/PzEyJEjDdp69+4tBg8eLIQQIj8/X2g0GvHll19K/enp6UKpVIqff/5ZCCHE+fPnBQBx4sQJKWbPnj1CoVCImzdvCiGEWL58uahWrZrIzs6WYqZNmybq1q1bojwzMjIEAJGRkVG2EyUiIqqkSvMaatSZkjZt2iAyMhIXL14EAJw+fRp//PEHunXrBgBITEyETqeDj4+PtI9arUarVq0QHR0NAIiOjoatrS1atGghxfj4+MDExATHjh2TYtq3bw9zc3MpxtfXFwkJCbh3716hvLKzs6HX6w02IiIiqlhGXWZ++vTp0Ov1qFevHkxNTZGXl4dPP/0UgwcPBgDodDoAgJOTk8F+Tk5OUp9Op4Ojo6NBv5mZGezs7AxiPDw8Co1R0FetWjWDvvnz52POnDnldJZERERUEkYtSjZt2oT169cjLCwM9evXR2xsLAIDA+Hi4gJ/f3+j5RUcHIygoCDpccGHCVUkD49rFTo+kRwkJrobOwUikjGjFiVTpkzB9OnTMWDAAABAw4YNcf36dcyfPx/+/v7QaDQAgJSUFDg7O0v7paSkoEmTJgAAjUaD1NRUg3EfP36MtLQ0aX+NRoOUlBSDmILHBTFPUiqVUCqV5XOSREREVCJGvabk4cOHMDExTMHU1BT5+fkAAA8PD2g0GkRGRkr9er0ex44dg1arBQBotVqkp6cjJiZGijlw4ADy8/PRqlUrKSYqKgq5ublSTEREBOrWrVvorRsiIiIyDqMWJT169MCnn36K8PBwXLt2Ddu2bcPChQvxzjvvAPjnY44DAwMxb9487Ny5E3FxcRg2bBhcXFzQq1cvAICXlxe6du2KMWPG4Pjx4zhy5AgmTJiAAQMGwMXFBQAwaNAgmJubY9SoUTh37hw2btyIJUuWGLxFQ0RERMZl1Ldvvv76a8ycORPvv/8+UlNT4eLigvfeew8hISFSzNSpU/HgwQOMHTsW6enpaNeuHfbu3QsLCwspZv369ZgwYQI6deoEExMT9OnTB0uXLpX61Wo19u/fj4CAADRv3hzVq1dHSEiIwVomREREZFwKIZ5YPpWKpNfroVarkZGRAZVKVSHH4IWuVBnwQleiyqc0r6H87BsiIiKSBRYlREREJAssSoiIiEgWWJQQERGRLLAoISIiIllgUUJERESywKKEiIiIZIFFCREREckCixIiIiKSBRYlREREJAssSoiIiEgWWJQQERGRLLAoISIiIllgUUJERESywKKEiIiIZIFFCREREckCixIiIiKSBRYlREREJAssSoiIiEgWWJQQERGRLLAoISIiIllgUUJERESywKKEiIiIZIFFCREREckCixIiIiKSBaMWJe7u7lAoFIW2gIAAAEBWVhYCAgJgb28PGxsb9OnTBykpKQZjJCUlwc/PD1ZWVnB0dMSUKVPw+PFjg5hDhw6hWbNmUCqV8PT0xJo1a17WKRIREVEJGbUoOXHiBG7duiVtERERAIB3330XADBp0iT8+uuv2Lx5Mw4fPozk5GT07t1b2j8vLw9+fn7IycnB0aNHsXbtWqxZswYhISFSTGJiIvz8/PDGG28gNjYWgYGBGD16NPbt2/dyT5aIiIieSSGEEMZOokBgYCB27dqFS5cuQa/Xw8HBAWFhYejbty8AID4+Hl5eXoiOjkbr1q2xZ88edO/eHcnJyXBycgIArFy5EtOmTcPt27dhbm6OadOmITw8HGfPnpWOM2DAAKSnp2Pv3r0lykuv10OtViMjIwMqlar8TxyAh8e1ChmXSE4SE92NnQIRvWSleQ2VzTUlOTk5WLduHUaOHAmFQoGYmBjk5ubCx8dHiqlXrx5q1qyJ6OhoAEB0dDQaNmwoFSQA4OvrC71ej3PnzkkxT45REFMwBhEREcmDmbETKLB9+3akp6dj+PDhAACdTgdzc3PY2toaxDk5OUGn00kxTxYkBf0Ffc+K0ev1ePToESwtLQvlkp2djezsbOmxXq9/oXMjIiKi55PNTMl///tfdOvWDS4uLsZOBfPnz4darZY2V1dXY6dERET0ryeLouT69ev47bffMHr0aKlNo9EgJycH6enpBrEpKSnQaDRSzNN34xQ8fl6MSqUqcpYEAIKDg5GRkSFtN27ceKHzIyIioueTRVGyevVqODo6ws/PT2pr3rw5qlSpgsjISKktISEBSUlJ0Gq1AACtVou4uDikpqZKMREREVCpVPD29pZinhyjIKZgjKIolUqoVCqDjYiIiCqW0YuS/Px8rF69Gv7+/jAz+79LXNRqNUaNGoWgoCAcPHgQMTExGDFiBLRaLVq3bg0A6NKlC7y9vTF06FCcPn0a+/btw4wZMxAQEAClUgkAGDduHK5evYqpU6ciPj4ey5cvx6ZNmzBp0iSjnC8REREVzegXuv72229ISkrCyJEjC/UtWrQIJiYm6NOnD7Kzs+Hr64vly5dL/aampti1axfGjx8PrVYLa2tr+Pv7Y+7cuVKMh4cHwsPDMWnSJCxZsgQ1atTAqlWr4Ovr+1LOj4iIiEpGVuuUyBXXKSEqH1ynhKjy+Z9cp4SIiIgqNxYlREREJAssSoiIiEgWWJQQERGRLLAoISIiIllgUUJERESywKKEiIiIZIFFCREREckCixIiIiKSBRYlREREJAssSoiIiEgWWJQQERGRLLAoISIiIllgUUJERESywKKEiIiIZIFFCREREckCixIiIiKSBRYlREREJAssSoiIiEgWWJQQERGRLLAoISIiIllgUUJERESywKKEiIiIZIFFCREREckCixIiIiKSBRYlREREJAtGL0pu3ryJIUOGwN7eHpaWlmjYsCFOnjwp9QshEBISAmdnZ1haWsLHxweXLl0yGCMtLQ2DBw+GSqWCra0tRo0ahczMTIOYM2fO4PXXX4eFhQVcXV0RGhr6Us6PiIiISsaoRcm9e/fQtm1bVKlSBXv27MH58+exYMECVKtWTYoJDQ3F0qVLsXLlShw7dgzW1tbw9fVFVlaWFDN48GCcO3cOERER2LVrF6KiojB27FipX6/Xo0uXLnBzc0NMTAy+/PJLzJ49G999991LPV8iIiIqnkIIIYx18OnTp+PIkSP4/fffi+wXQsDFxQUfffQRJk+eDADIyMiAk5MT1qxZgwEDBuDChQvw9vbGiRMn0KJFCwDA3r178dZbb+Hvv/+Gi4sLVqxYgY8//hg6nQ7m5ubSsbdv3474+Pjn5qnX66FWq5GRkQGVSlVOZ2/Iw+NahYxLJCeJie7GToGIXrLSvIYadaZk586daNGiBd599104OjqiadOm+P7776X+xMRE6HQ6+Pj4SG1qtRqtWrVCdHQ0ACA6Ohq2trZSQQIAPj4+MDExwbFjx6SY9u3bSwUJAPj6+iIhIQH37t2r6NMkIiKiEjBqUXL16lWsWLECderUwb59+zB+/HhMnDgRa9euBQDodDoAgJOTk8F+Tk5OUp9Op4Ojo6NBv5mZGezs7AxiihrjyWM8KTs7G3q93mAjIiKiimVmzIPn5+ejRYsW+OyzzwAATZs2xdmzZ7Fy5Ur4+/sbLa/58+djzpw5Rjs+ERFRZWTUmRJnZ2d4e3sbtHl5eSEpKQkAoNFoAAApKSkGMSkpKVKfRqNBamqqQf/jx4+RlpZmEFPUGE8e40nBwcHIyMiQths3bpT1FImIiKiEjFqUtG3bFgkJCQZtFy9ehJubGwDAw8MDGo0GkZGRUr9er8exY8eg1WoBAFqtFunp6YiJiZFiDhw4gPz8fLRq1UqKiYqKQm5urhQTERGBunXrGtzpU0CpVEKlUhlsREREVLGMWpRMmjQJf/75Jz777DNcvnwZYWFh+O677xAQEAAAUCgUCAwMxLx587Bz507ExcVh2LBhcHFxQa9evQD8M7PStWtXjBkzBsePH8eRI0cwYcIEDBgwAC4uLgCAQYMGwdzcHKNGjcK5c+ewceNGLFmyBEFBQcY6dSIiInqKUa8padmyJbZt24bg4GDMnTsXHh4eWLx4MQYPHizFTJ06FQ8ePMDYsWORnp6Odu3aYe/evbCwsJBi1q9fjwkTJqBTp04wMTFBnz59sHTpUqlfrVZj//79CAgIQPPmzVG9enWEhIQYrGVCRERExmXUdUr+V3CdEqLywXVKiCqf/5l1SoiIiIgKsCghIiIiWWBRQkRERLLAooSIiIhkgUUJERERyQKLEiIiIpIFFiVEREQkCyxKiIiISBZYlBAREZEssCghIiIiWWBRQkRERLLAooSIiIhkgUUJERERyQKLEiIiIpIFFiVEREQkCyxKiIiISBZYlBAREZEssCghIiIiWWBRQkRERLLAooSIiIhkgUUJERERyQKLEiIiIpKFMhcl6enpWLVqFYKDg5GWlgYAOHXqFG7evFluyREREVHlYVaWnc6cOQMfHx+o1Wpcu3YNY8aMgZ2dHbZu3YqkpCT8+OOP5Z0nERER/cuVaaYkKCgIw4cPx6VLl2BhYSG1v/XWW4iKiiq35IiIiKjyKFNRcuLECbz33nuF2l955RXodLoXToqIiIgqnzIVJUqlEnq9vlD7xYsX4eDgUOJxZs+eDYVCYbDVq1dP6s/KykJAQADs7e1hY2ODPn36ICUlxWCMpKQk+Pn5wcrKCo6OjpgyZQoeP35sEHPo0CE0a9YMSqUSnp6eWLNmTelOmIiIiCpcmYqSnj17Yu7cucjNzQUAKBQKJCUlYdq0aejTp0+pxqpfvz5u3bolbX/88YfUN2nSJPz666/YvHkzDh8+jOTkZPTu3Vvqz8vLg5+fH3JycnD06FGsXbsWa9asQUhIiBSTmJgIPz8/vPHGG4iNjUVgYCBGjx6Nffv2leXUiYiIqIIohBCitDtlZGSgb9++OHnyJO7fvw8XFxfodDpotVrs3r0b1tbWJRpn9uzZ2L59O2JjY4s8hoODA8LCwtC3b18AQHx8PLy8vBAdHY3WrVtjz5496N69O5KTk+Hk5AQAWLlyJaZNm4bbt2/D3Nwc06ZNQ3h4OM6ePSuNPWDAAKSnp2Pv3r0lylOv10OtViMjIwMqlapE+5SWh8e1ChmXSE4SE92NnQIRvWSleQ0t00yJWq1GREQEfv31VyxduhQTJkzA7t27cfjw4RIXJAUuXboEFxcX1KpVC4MHD0ZSUhIAICYmBrm5ufDx8ZFi69Wrh5o1ayI6OhoAEB0djYYNG0oFCQD4+vpCr9fj3LlzUsyTYxTEFIxBRERE8lCmW4ILtGvXDu3atSvz/q1atcKaNWtQt25d3Lp1C3PmzMHrr7+Os2fPQqfTwdzcHLa2tgb7ODk5SRfT6nQ6g4KkoL+g71kxer0ejx49gqWlZaG8srOzkZ2dLT0u6voZIiIiKl8lLkqWLl1a4kEnTpxYorhu3bpJXzdq1AitWrWCm5sbNm3aVGSx8LLMnz8fc+bMMdrxiYiIKqMSFyWLFi0yeHz79m08fPhQmslIT0+X7oApaVHyNFtbW7z66qu4fPkyOnfujJycHKSnpxvMlqSkpECj0QAANBoNjh8/bjBGwd05T8Y8fcdOSkoKVCpVsYVPcHAwgoKCpMd6vR6urq5lOiciIiIqmRJfU5KYmChtn376KZo0aYILFy4gLS0NaWlpuHDhApo1a4ZPPvmkzMlkZmbiypUrcHZ2RvPmzVGlShVERkZK/QkJCUhKSoJWqwUAaLVaxMXFITU1VYqJiIiASqWCt7e3FPPkGAUxBWMURalUQqVSGWxERERUscp0903t2rWxZcsWNG3a1KA9JiYGffv2RWJiYonGmTx5Mnr06AE3NzckJydj1qxZiI2Nxfnz5+Hg4IDx48dj9+7dWLNmDVQqFT744AMAwNGjRwH8c0twkyZN4OLigtDQUOh0OgwdOhSjR4/GZ599BuCfYqpBgwYICAjAyJEjceDAAUycOBHh4eHw9fUtUZ68+4aofPDuG6LKpzSvoWW60PXWrVuFFigD/ikSnn6r5Fn+/vtvDBw4EHfv3oWDgwPatWuHP//8U1qAbdGiRTAxMUGfPn2QnZ0NX19fLF++XNrf1NQUu3btwvjx46HVamFtbQ1/f3/MnTtXivHw8EB4eDgmTZqEJUuWoEaNGli1alWJCxIiIiJ6Oco0U9KjRw/cvHkTq1atQrNmzQD8M0syduxYvPLKK9i5c2e5J2pMnCkhKh+cKSGqfCp8nZIffvgBGo0GLVq0gFKphFKpxGuvvQYnJyesWrWqTEkTERFR5Vamt28cHBywe/duXLx4EfHx8QD+Wdjs1VdfLdfkiIiIqPJ4ocXTXn31VRYiREREVC7KXJT8/fff2LlzJ5KSkpCTk2PQt3DhwhdOjIiIiCqXMhUlkZGR6NmzJ2rVqoX4+Hg0aNAA165dgxBCuvCViIiIqDTKdKFrcHAwJk+ejLi4OFhYWOCXX37BjRs30KFDB7z77rvlnSMRERFVAmUqSi5cuIBhw4YBAMzMzPDo0SPY2Nhg7ty5+OKLL8o1QSIiIqocylSUWFtbS9eRODs748qVK1LfnTt3yiczIiIiqlTKdE1J69at8ccff8DLywtvvfUWPvroI8TFxWHr1q1o3bp1eedIRERElUCZipKFCxciMzMTADBnzhxkZmZi48aNqFOnDu+8ISIiojIpU1FSq1Yt6Wtra2usXLmy3BIiIiKiyqlM15QQERERlbcSz5RUq1YNCoWiRLFpaWllToiIiIgqpxIXJYsXL5a+vnv3LubNmwdfX19otVoAQHR0NPbt24eZM2eWe5JERET076cQQojS7tSnTx+88cYbmDBhgkH7smXL8Ntvv2H79u3llZ8slOZjl8vKw+NahYxLJCeJie7GToGIXrLSvIaW6ZqSffv2oWvXroXau3btit9++60sQxIREVElV6aixN7eHjt27CjUvmPHDtjb279wUkRERFT5lOmW4Dlz5mD06NE4dOgQWrVqBQA4duwY9u7di++//75cEyQiIqLKoUxFyfDhw+Hl5YWlS5di69atAAAvLy/88ccfUpFCREREVBplKkoAoFWrVli/fn155kJERESVWImLEr1eL101q9frnxlbUXeoEBER0b9XqRZPu3XrFhwdHWFra1vkQmpCCCgUCuTl5ZVrkkRERPTvV+Ki5MCBA7CzswMAHDx4sMISIiIiosqpxEVJhw4dpK89PDzg6upaaLZECIEbN26UX3ZERERUaZRpnRIPDw/cvn27UHtaWho8PDxeOCkiIiKqfMpUlBRcO/K0zMxMWFhYvHBSREREVPmUqigJCgpCUFAQFAoFZs6cKT0OCgrChx9+iP79+6NJkyZlSuTzzz+HQqFAYGCg1JaVlYWAgADY29vDxsYGffr0QUpKisF+SUlJ8PPzg5WVFRwdHTFlyhQ8fvzYIObQoUNo1qwZlEolPD09sWbNmjLlSERERBWnVOuU/PXXXwD+mSmJi4uDubm51Gdubo7GjRtj8uTJpU7ixIkT+Pbbb9GoUSOD9kmTJiE8PBybN2+GWq3GhAkT0Lt3bxw5cgQAkJeXBz8/P2g0Ghw9ehS3bt3CsGHDUKVKFXz22WcAgMTERPj5+WHcuHFYv349IiMjMXr0aDg7O8PX17fUuRIREVHFKNOnBI8YMQJLliwpl/VIMjMz0axZMyxfvhzz5s1DkyZNsHjxYmRkZMDBwQFhYWHo27cvACA+Ph5eXl6Ijo5G69atsWfPHnTv3h3JyclwcnICAKxcuRLTpk3D7du3YW5ujmnTpiE8PBxnz56VjjlgwACkp6dj7969JcqRnxJMVD74KcFElU+Ff0rw6tWry+3FOSAgAH5+fvDx8TFoj4mJQW5urkF7vXr1ULNmTURHRwMAoqOj0bBhQ6kgAQBfX1/o9XqcO3dOinl6bF9fX2mMomRnZ0Ov1xtsREREVLHKtMz8gwcP8PnnnyMyMhKpqanIz8836L969WqJxtmwYQNOnTqFEydOFOrT6XQwNzeHra2tQbuTkxN0Op0U82RBUtBf0PesGL1ej0ePHsHS0rLQsefPn485c+aU6ByIiIiofJSpKBk9ejQOHz6MoUOHwtnZucg7cZ7nxo0b+PDDDxERESG7O3aCg4MRFBQkPdbr9XB1dTViRkRERP9+ZSpK9uzZg/DwcLRt27bMB46JiUFqaiqaNWsmteXl5SEqKgrLli3Dvn37kJOTg/T0dIPZkpSUFGg0GgCARqPB8ePHDcYtuDvnyZin79hJSUmBSqUqcpYEAJRKJZRKZZnPjYiIiEqvTNeUVKtWTVpyvqw6deqEuLg4xMbGSluLFi0wePBg6esqVaogMjJS2ichIQFJSUnQarUAAK1Wi7i4OKSmpkoxERERUKlU8Pb2lmKeHKMgpmAMIiIikocyzZR88sknCAkJwdq1a2FlZVWmA1etWhUNGjQwaLO2toa9vb3UPmrUKAQFBcHOzg4qlQoffPABtFotWrduDQDo0qULvL29MXToUISGhkKn02HGjBkICAiQZjrGjRuHZcuWYerUqRg5ciQOHDiATZs2ITw8vEx5ExERUcUoU1GyYMECXLlyBU5OTnB3d0eVKlUM+k+dOlUuyS1atAgmJibo06cPsrOz4evri+XLl0v9pqam2LVrF8aPHw+tVgtra2v4+/tj7ty5UoyHhwfCw8MxadIkLFmyBDVq1MCqVau4RgkREZHMlGmdkufdmTJr1qwyJyRHXKeEqHxwnRKiyqc0r6Flmin5txUdREREZHxlutCViIiIqLyVaaYkLy8PixYtwqZNm5CUlIScnByD/rS0tHJJjoiIiCqPMs2UzJkzBwsXLkT//v2RkZGBoKAg9O7dGyYmJpg9e3Y5p0hERESVQZmKkvXr1+P777/HRx99BDMzMwwcOBCrVq1CSEgI/vzzz/LOkYiIiCqBMhUlOp0ODRs2BADY2NggIyMDANC9e3eu/0FERERlUqaipEaNGrh16xYAoHbt2ti/fz8A4MSJE1yenYiIiMqkTEXJO++8Iy3d/sEHH2DmzJmoU6cOhg0bhpEjR5ZrgkRERFQ5lOnum88//1z6un///qhZsyaio6NRp04d9OjRo9ySIyIiosqjTEXJ07RaLT/gjoiIiF5ImYqSH3/88Zn9w4YNK1MyREREVHmVqSj58MMPDR7n5ubi4cOHMDc3h5WVFYsSIiIiKrUyXeh67949gy0zMxMJCQlo164dfv755/LOkYiIiCqBcvvsmzp16uDzzz8vNItCREREVBLl+oF8ZmZmSE5OLs8hiYiIqJIo0zUlO3fuNHgshMCtW7ewbNkytG3btlwSIyIiosqlTEVJr169DB4rFAo4ODjgzTffxIIFC8ojLyIiIqpkylSU5OfnAwBu374Nc3NzqNXqck2KiIiIKp9SX1OSnp6OgIAAVK9eHRqNBnZ2dtBoNAgODsbDhw8rIkciIiKqBEo1U5KWlgatVoubN29i8ODB8PLyAgCcP38eX3/9NSIiIvDHH3/gzJkz+PPPPzFx4sQKSZqIiIj+fUpVlMydOxfm5ua4cuUKnJycCvV16dIFQ4cOxf79+7F06dJyTZSIiIj+3UpVlGzfvh3ffvttoYIEADQaDUJDQ/HWW29h1qxZ8Pf3L7ckiYiI6N+vVNeU3Lp1C/Xr1y+2v0GDBjAxMcGsWbNeODEiIiKqXEpVlFSvXh3Xrl0rtj8xMRGOjo4vmhMRERFVQqUqSnx9ffHxxx8jJyenUF92djZmzpyJrl27lltyREREVHmU+kLXFi1aoE6dOggICEC9evUghMCFCxewfPlyZGdn48cff6yoXImIiOhfrFQzJTVq1EB0dDS8vb0RHByMXr164Z133sHHH38Mb29vHDlyBDVr1izxeCtWrECjRo2gUqmgUqmg1WqxZ88eqT8rKwsBAQGwt7eHjY0N+vTpg5SUFIMxkpKS4OfnBysrKzg6OmLKlCl4/PixQcyhQ4fQrFkzKJVKeHp6Ys2aNaU5bSIiInoJSr2iq4eHB/bs2YN79+7h0qVLAABPT0/Y2dmV+uA1atTA559/jjp16kAIgbVr1+Ltt9/GX3/9hfr162PSpEkIDw/H5s2boVarMWHCBPTu3RtHjhwBAOTl5cHPzw8ajQZHjx7FrVu3MGzYMFSpUgWfffYZgH+uc/Hz88O4ceOwfv16REZGYvTo0XB2doavr2+pcyYiIqKKoRBCCGMn8SQ7Ozt8+eWX6Nu3LxwcHBAWFoa+ffsCAOLj4+Hl5YXo6Gi0bt0ae/bsQffu3ZGcnCzdprxy5UpMmzZNWgJ/2rRpCA8Px9mzZ6VjDBgwAOnp6di7d2+JctLr9VCr1cjIyIBKpSr/kwbg4XGtQsYlkpPERHdjp0BEL1lpXkNLvcx8RcnLy8OGDRvw4MEDaLVaxMTEIDc3Fz4+PlJMvXr1ULNmTURHRwMAoqOj0bBhQ4N1U3x9faHX63Hu3Dkp5skxCmIKxihKdnY29Hq9wUZEREQVy+hFSVxcHGxsbKBUKjFu3Dhs27YN3t7e0Ol0MDc3h62trUG8k5MTdDodAECn0xVayK3g8fNi9Ho9Hj16VGRO8+fPh1qtljZXV9fyOFUiIiJ6BqMXJXXr1kVsbCyOHTuG8ePHw9/fH+fPnzdqTsHBwcjIyJC2GzduGDUfIiKiyqDUF7qWN3Nzc3h6egIAmjdvjhMnTmDJkiXo378/cnJykJ6ebjBbkpKSAo1GA+Cfpe2PHz9uMF7B3TlPxjx9x05KSgpUKhUsLS2LzEmpVEKpVJbL+REREVHJGH2m5Gn5+fnIzs5G8+bNUaVKFURGRkp9CQkJSEpKglarBQBotVrExcUhNTVViomIiIBKpYK3t7cU8+QYBTEFYxAREZE8GHWmJDg4GN26dUPNmjVx//59hIWF4dChQ9i3bx/UajVGjRqFoKAg2NnZQaVS4YMPPoBWq0Xr1q0BAF26dIG3tzeGDh2K0NBQ6HQ6zJgxAwEBAdJMx7hx47Bs2TJMnToVI0eOxIEDB7Bp0yaEh4cb89SJiIjoKUYtSlJTUzFs2DDcunULarUajRo1wr59+9C5c2cAwKJFi2BiYoI+ffogOzsbvr6+WL58ubS/qakpdu3ahfHjx0Or1cLa2hr+/v6YO3euFOPh4YHw8HBMmjQJS5YsQY0aNbBq1SquUUJERCQzslunRI64TglR+eA6JUSVz//kOiVERERUubEoISIiIllgUUJERESywKKEiIiIZIFFCREREckCixIiIiKSBRYlREREJAssSoiIiEgWWJQQERGRLLAoISIiIllgUUJERESywKKEiIiIZIFFCREREckCixIiIiKSBRYlREREJAssSoiIiEgWWJQQERGRLLAoISIiIllgUUJERESywKKEiIiIZIFFCREREckCixIiIiKSBRYlREREJAssSoiIiEgWWJQQERGRLLAoISIiIlkwalEyf/58tGzZElWrVoWjoyN69eqFhIQEg5isrCwEBATA3t4eNjY26NOnD1JSUgxikpKS4OfnBysrKzg6OmLKlCl4/PixQcyhQ4fQrFkzKJVKeHp6Ys2aNRV9ekRERFQKRi1KDh8+jICAAPz555+IiIhAbm4uunTpggcPHkgxkyZNwq+//orNmzfj8OHDSE5ORu/evaX+vLw8+Pn5IScnB0ePHsXatWuxZs0ahISESDGJiYnw8/PDG2+8gdjYWAQGBmL06NHYt2/fSz1fIiIiKp5CCCGMnUSB27dvw9HREYcPH0b79u2RkZEBBwcHhIWFoW/fvgCA+Ph4eHl5ITo6Gq1bt8aePXvQvXt3JCcnw8nJCQCwcuVKTJs2Dbdv34a5uTmmTZuG8PBwnD17VjrWgAEDkJ6ejr179z43L71eD7VajYyMDKhUqgo5dw+PaxUyLpGcJCa6GzsFInrJSvMaavaSciqRjIwMAICdnR0AICYmBrm5ufDx8ZFi6tWrh5o1a0pFSXR0NBo2bCgVJADg6+uL8ePH49y5c2jatCmio6MNxiiICQwMLDKP7OxsZGdnS4/1en15nSIR/Q+65uFh7BSIKpx7YqKxU5DPha75+fkIDAxE27Zt0aBBAwCATqeDubk5bG1tDWKdnJyg0+mkmCcLkoL+gr5nxej1ejx69KhQLvPnz4darZY2V1fXcjlHIiIiKp5sipKAgACcPXsWGzZsMHYqCA4ORkZGhrTduHHD2CkRERH968ni7ZsJEyZg165diIqKQo0aNaR2jUaDnJwcpKenG8yWpKSkQKPRSDHHjx83GK/g7pwnY56+YyclJQUqlQqWlpaF8lEqlVAqleVybkRERFQyRp0pEUJgwoQJ2LZtGw4cOACPp963bd68OapUqYLIyEipLSEhAUlJSdBqtQAArVaLuLg4pKamSjERERFQqVTw9vaWYp4coyCmYAwiIiIyPqPOlAQEBCAsLAw7duxA1apVpWtA1Go1LC0toVarMWrUKAQFBcHOzg4qlQoffPABtFotWrduDQDo0qULvL29MXToUISGhkKn02HGjBkICAiQZjvGjRuHZcuWYerUqRg5ciQOHDiATZs2ITw83GjnTkRERIaMOlOyYsUKZGRkoGPHjnB2dpa2jRs3SjGLFi1C9+7d0adPH7Rv3x4ajQZbt26V+k1NTbFr1y6YmppCq9ViyJAhGDZsGObOnSvFeHh4IDw8HBEREWjcuDEWLFiAVatWwdfX96WeLxERERVPVuuUyBXXKSEqH/+r65TwlmCqDCrqluDSvIbK5u4bIiIiqtxYlBAREZEssCghIiIiWWBRQkRERLLAooSIiIhkgUUJERERyQKLEiIiIpIFFiVEREQkCyxKiIiISBZYlBAREZEssCghIiIiWWBRQkRERLLAooSIiIhkgUUJERERyQKLEiIiIpIFFiVEREQkCyxKiIiISBZYlBAREZEssCghIiIiWWBRQkRERLLAooSIiIhkgUUJERERyQKLEiIiIpIFFiVEREQkCyxKiIiISBaMWpRERUWhR48ecHFxgUKhwPbt2w36hRAICQmBs7MzLC0t4ePjg0uXLhnEpKWlYfDgwVCpVLC1tcWoUaOQmZlpEHPmzBm8/vrrsLCwgKurK0JDQyv61IiIiKiUjFqUPHjwAI0bN8Y333xTZH9oaCiWLl2KlStX4tixY7C2toavry+ysrKkmMGDB+PcuXOIiIjArl27EBUVhbFjx0r9er0eXbp0gZubG2JiYvDll19i9uzZ+O677yr8/IiIiKjkFEIIYewkAEChUGDbtm3o1asXgH9mSVxcXPDRRx9h8uTJAICMjAw4OTlhzZo1GDBgAC5cuABvb2+cOHECLVq0AADs3bsXb731Fv7++2+4uLhgxYoV+Pjjj6HT6WBubg4AmD59OrZv3474+PgS5abX66FWq5GRkQGVSlX+Jw/Aw+NahYxLJCeJie7GTqFMrnl4GDsFogrnnphYIeOW5jVUtteUJCYmQqfTwcfHR2pTq9Vo1aoVoqOjAQDR0dGwtbWVChIA8PHxgYmJCY4dOybFtG/fXipIAMDX1xcJCQm4d+/eSzobIiIieh4zYydQHJ1OBwBwcnIyaHdycpL6dDodHB0dDfrNzMxgZ2dnEOPx1H85BWPqdDpUq1at0LGzs7ORnZ0tPdbr9S94NkRERPQ8sp0pMab58+dDrVZLm6urq7FTIiIi+teTbVGi0WgAACkpKQbtKSkpUp9Go0FqaqpB/+PHj5GWlmYQU9QYTx7jacHBwcjIyJC2GzduvPgJERER0TPJtijx8PCARqNBZGSk1KbX63Hs2DFotVoAgFarRXp6OmJiYqSYAwcOID8/H61atZJioqKikJubK8VERESgbt26Rb51AwBKpRIqlcpgIyIioopl1KIkMzMTsbGxiI2NBfDPxa2xsbFISkqCQqFAYGAg5s2bh507dyIuLg7Dhg2Di4uLdIeOl5cXunbtijFjxuD48eM4cuQIJkyYgAEDBsDFxQUAMGjQIJibm2PUqFE4d+4cNm7ciCVLliAoKMhIZ01ERERFMeqFridPnsQbb7whPS4oFPz9/bFmzRpMnToVDx48wNixY5Geno527dph7969sLCwkPZZv349JkyYgE6dOsHExAR9+vTB0qVLpX61Wo39+/cjICAAzZs3R/Xq1RESEmKwlgkREREZn2zWKZEzrlNCVD64TgmRfHGdEiIiIqL/j0UJERERyQKLEiIiIpIFFiVEREQkCyxKiIiISBZYlBAREZEssCghIiIiWWBRQkRERLLAooSIiIhkgUUJERERyQKLEiIiIpIFFiVEREQkCyxKiIiISBZYlBAREZEssCghIiIiWWBRQkRERLLAooSIiIhkgUUJERERyQKLEiIiIpIFFiVEREQkCyxKiIiISBZYlBAREZEssCghIiIiWWBRQkRERLLAooSIiIhkgUUJERERyUKlKkq++eYbuLu7w8LCAq1atcLx48eNnRIRERH9f5WmKNm4cSOCgoIwa9YsnDp1Co0bN4avry9SU1ONnRoRERGhEhUlCxcuxJgxYzBixAh4e3tj5cqVsLKywg8//GDs1IiIiAiVpCjJyclBTEwMfHx8pDYTExP4+PggOjraiJkRERFRATNjJ/Ay3LlzB3l5eXBycjJod3JyQnx8fKH47OxsZGdnS48zMjIAAHq9vsJyzM+/X2FjE8lFRf4OVaT7+fnGToGowlXU72fBuEKI58ZWiqKktObPn485c+YUand1dTVCNkT/Hmq1sTMgomJV8C/o/fv3oX7OMSpFUVK9enWYmpoiJSXFoD0lJQUajaZQfHBwMIKCgqTH+fn5SEtLg729PRQKRYXnSxVPr9fD1dUVN27cgEqlMnY6RPQE/n7+uwghcP/+fbi4uDw3tlIUJebm5mjevDkiIyPRq1cvAP8UGpGRkZgwYUKheKVSCaVSadBma2v7EjKll02lUvGPHpFM8ffz3+N5MyQFKkVRAgBBQUHw9/dHixYt8Nprr2Hx4sV48OABRowYYezUiIiICJWoKOnfvz9u376NkJAQ6HQ6NGnSBHv37i108SsREREZR6UpSgBgwoQJRb5dQ5WPUqnErFmzCr1NR0TGx9/PykshSnKPDhEREVEFqxSLpxEREZH8sSghIqJylZ+fj6+++gp//fWXsVOh/zEsSoiIqFzNmDEDUVFRaNSokbFTkcycORNjx44t1T6tW7fGL7/8UkEZUVFYlJDRdOzYEYGBgcZOo9wNHToUn332WYnj79y5A0dHR/z9998VmBXR892+fRvjx49HzZo1oVQqodFo4OvriyNHjpR4jO3bt+PQoUPYsGEDTE1NKzDbktPpdFiyZAk+/vhjqS0qKgo9evSAi4sLFAoFtm/fXmi/GTNmYPr06cjnxwy8NCxKqEINHz4cCoWi0Hb58mVs3boVn3zyibFTLFenT5/G7t27MXHiRKlNCIGQkBA4OzvD0tISPj4+uHTpktRfvXp1DBs2DLNmzTJGykSSPn364K+//sLatWtx8eJF7Ny5Ex07dsTdu3dLPEavXr1w9OhRWFlZFdmfk5NTXumW2KpVq9CmTRu4ublJbQ8ePEDjxo3xzTffFLtft27dcP/+fezZs+dlpEkAIIgqkL+/v+jatau4deuWwfb48eMKP3Z2dnaFH+Npo0aNEu+9955B2+effy7UarXYvn27OH36tOjZs6fw8PAQjx49kmLOnj0rlEqluHv37stOmUgIIcS9e/cEAHHo0KFnxi1YsEA0aNBAWFlZiRo1aojx48eL+/fvS/2rV68WarVaejxr1izRuHFj8f333wt3d3ehUCiEEELs2bNHtG3bVqjVamFnZyf8/PzE5cuXpf0SExMFALFx40bRrl07YWFhIVq0aCESEhLE8ePHRfPmzYW1tbXo2rWrSE1NfWbO9evXF8uWLSu2H4DYtm1bkX0jRowQQ4YMeeb4VH44U0IVrmAa+MnN1NS00Ns32dnZmDZtGlxdXaFUKuHp6Yn//ve/AIC8vDyMGjUKHh4esLS0RN26dbFkyRKD4wwfPhy9evXCp59+ChcXF9StWxcA8NNPP6FFixaoWrUqNBoNBg0ahNTUVGm/Q4cOQaFQYN++fWjatCksLS3x5ptvIjU1FXv27IGXlxdUKhUGDRqEhw8fFnueeXl52LJlC3r06CG1CSGwePFizJgxA2+//TYaNWqEH3/8EcnJyQbTxfXr14eLiwu2bdv2It9qojKzsbGBjY0Ntm/fbvAp6U8zMTHB0qVLce7cOaxduxYHDhzA1KlTnzn25cuX8csvv2Dr1q2IjY0F8M9MRVBQEE6ePInIyEiYmJjgnXfeKfRWyaxZszBjxgycOnUKZmZmGDRoEKZOnYolS5bg999/x+XLlxESElLssdPS0nD+/Hm0aNGi5N+MJ7z22mv4/fffy7QvlYGxqyL6d/P39xdvv/12kX0dOnQQH374ofS4X79+wtXVVWzdulVcuXJF/Pbbb2LDhg1CCCFycnJESEiIOHHihLh69apYt26dsLKyEhs3bjQ4lo2NjRg6dKg4e/asOHv2rBBCiP/+979i9+7d4sqVKyI6OlpotVrRrVs3ab+DBw8KAKJ169bijz/+EKdOnRKenp6iQ4cOokuXLuLUqVMiKipK2Nvbi88//7zYcz116pQAIHQ6ndR25coVAUD89ddfBrHt27cXEydONGjr37+/8Pf3f9a3k6hCbdmyRVSrVk1YWFiINm3aiODgYHH69Oln7rN582Zhb28vPS5qpqRKlSrPnc24ffu2ACDi4uKEEP83U7Jq1Sop5ueffxYARGRkpNQ2f/58Ubdu3WLH/euvvwQAkZSUVGwMnjFTsmPHDmFiYiLy8vKemT+Vj0q1oisZx65du2BjYyM97tatGzZv3mwQc/HiRWzatAkRERHw8fEBANSqVUvqr1KlCubMmSM99vDwQHR0NDZt2oR+/fpJ7dbW1li1ahXMzc2ltpEjR0pf16pVC0uXLkXLli2RmZlpkNe8efPQtm1bAMCoUaMQHByMK1euSHn07dsXBw8exLRp04o8z+vXr8PU1BSOjo5Sm06nA4BCH2fg5OQk9RVwcXHhLZRkVH369IGfnx9+//13/Pnnn9izZw9CQ0OxatUqDB8+HADw22+/Yf78+YiPj4der8fjx4+RlZWFhw8fFnsdiZubGxwcHAzaLl26hJCQEBw7dgx37tyRZkiSkpLQoEEDKe7JO3gKfo8aNmxo0PbkzOfTHj16BACwsLAoxXfi/1haWiI/Px/Z2dmwtLQs0xhUcnz7hircG2+8gdjYWGlbunRpoZjY2FiYmpqiQ4cOxY7zzTffoHnz5nBwcICNjQ2+++47JCUlGcQ0bNjQoCABgJiYGPTo0QM1a9ZE1apVpWM8ve/Tf/ysrKwMCqOS/PFTKpVQKBTFxjyLpaXlM98eInoZLCws0LlzZ8ycORNHjx7F8OHDpYuwr127hu7du6NRo0b45ZdfEBMTI10o+qwLWK2trQu19ejRA2lpafj+++9x7NgxHDt2rMhxqlSpIn1d8Lv1dNuz7o6pXr06AODevXvPPO/ipKWlwdramgXJS8KihCqctbU1PD09pc3Z2blQzPN+4Tds2IDJkydj1KhR2L9/P2JjYzFixIhCf8Ce/uP34MED+Pr6QqVSYf369Thx4oR03cbz/vg9+big7Xl//B4+fGgwrkajAQCkpKQYxKakpEh9BdLS0gr9N0lkbN7e3njw4AGAfwr8/Px8LFiwAK1bt8arr76K5OTkUo959+5dJCQkYMaMGejUqRO8vLzKXDQ8T+3ataFSqXD+/Pky7X/27Fk0bdq0nLOi4rAoIVlo2LAh8vPzcfjw4SL7jxw5gjZt2uD9999H06ZN4enpiStXrjx33Pj4eNy9exeff/45Xn/9ddSrV++Zsx0vokmTJgBg8MfPw8MDGo0GkZGRUpter8exY8eg1WoN9ucfPzKmu3fv4s0338S6detw5swZJCYmYvPmzQgNDcXbb78NAPD09ERubi6+/vprXL16FT/99BNWrlxZ6mNVq1YN9vb2+O6773D58mUcOHAAQUFB5X1KAP65MNfHxwd//PGHQXtmZqY0ewsAiYmJiI2NLTSD+vvvv6NLly4VkhsVxqKEZMHd3R3+/v4YOXIktm/fjsTERBw6dAibNm0CANSpUwcnT57Evn37cPHiRcycORMnTpx47rg1a9aEubm59Ed0586dFbY2ioODA5o1a2bwx0+hUCAwMBDz5s3Dzp07ERcXh2HDhsHFxQW9evWS4h4+fIiYmBj+8SOjsbGxQatWrbBo0SK0b98eDRo0wMyZMzFmzBgsW7YMANC4cWMsXLgQX3zxBRo0aID169dj/vz5pT6WiYkJNmzYgJiYGDRo0ACTJk3Cl19+Wd6nJBk9ejQ2bNhgMNN58uRJNG3aVPpHICgoCE2bNjW4k+fmzZs4evQoRowYUWG50VOMfaUt/buV5u6bR48eiUmTJglnZ2dhbm4uPD09xQ8//CCEECIrK0sMHz5cqNVqYWtrK8aPHy+mT58uGjdu/NxjhYWFCXd3d6FUKoVWqxU7d+40uCOm4O6be/fuSfs8fQeBEP+33sKzLF++XLRu3dqgLT8/X8ycOVM4OTkJpVIpOnXqJBISEgrl+Kw7CIio7PLz80XLli1FWFhYqfabOnWqGDNmTAVlRUVRCCGEsQsjon+LR48eoW7duti4cWOht2eepXXr1pg4cSIGDRpUgdkRVV6xsbGIi4vD0KFDS7zPggULMGTIkEJ3z1HFYVFCVM4OHTqE+/fvGyyi9ix37tzBDz/8gClTppT5zh0ion8DFiVEREQkC7zQlYiIiGSBRQkRERHJAosSIiIikgUWJURERCQLLEqIiIhIFliUENH/lGvXrkGhUEjLg1ek4cOHG6y827FjRwQGBlb4cYkqKxYlRP9it2/fxvjx41GzZk0olUpoNBr4+vriyJEjUoxCocD27dtLPba7uzsWL15cfsm+ZEIIfPfdd2jVqhVsbGxga2uLFi1aYPHixcV+WvPWrVvL/WMKni58iCozM2MnQEQVp0+fPsjJycHatWtRq1YtpKSkIDIyEnfv3jV2akY3dOhQbN26FTNmzMCyZcvg4OCA06dPY/HixXB3dy+yULCzs3v5iRJVJkZc4p6IKtC9e/cEAHHo0KFiY9zc3AQAaXNzcxNCCHH58mXRs2dP4ejoKKytrUWLFi1ERESEtF+HDh0M9iv4U1LU5wMtWrRIGleIfz5rqGXLlsLKykqo1WrRpk0bce3atWJzPHbsmGjSpIlQKpWiefPmYuvWrQafXSSEEIcOHRItW7YU5ubmQqPRiGnTponc3Nxix9y4caMAILZv316oLz8/X6SnpwshCn+e0tOf15SVlSU++ugj4eLiIqysrMRrr70mDh48KPUXfIbS3r17Rb169YS1tbXw9fUVycnJ0vfr6e9jwf5JSUni3XffFWq1WlSrVk307NlTJCYmFntORP8GfPuG6F/KxsYGNjY22L59O7Kzs4uMKfik5dWrV+PWrVvS48zMTLz11luIjIzEX3/9ha5du6JHjx7Sx7pv3boVNWrUwNy5c3Hr1i3cunWrRDk9fvwYvXr1QocOHXDmzBlER0dj7NixxS6vn5mZie7du8Pb2xsxMTGYPXs2Jk+ebBBz8+ZNvPXWW2jZsiVOnz6NFStW4L///S/mzZtXbB7r169H3bp18fbbbxfqUygUUKvVJTqfCRMmIDo6Ghs2bMCZM2fw7rvvomvXrrh06ZIU8/DhQ3z11Vf46aefEBUVhaSkJOkcJk+ejH79+qFr167S97FNmzbIzc2Fr68vqlatit9//x1HjhyBjY0NunbtipycnBLlRvQ/ydhVERFVnC1btohq1aoJCwsL0aZNGxEcHCxOnz5tEANAbNu27blj1a9fX3z99dfSYzc3N7Fo0SKDmOfNlNy9e/e5szdP+vbbb4W9vb149OiR1LZixQqDmZL//Oc/om7duiI/P1+K+eabb4SNjY3Iy8srclwvLy/Rs2fP5x7/WTMl169fF6ampuLmzZsG+3Tq1EkEBwcLIf6ZKQEgLl++bJCbk5NTsccQQoiffvqp0DllZ2cLS0tLsW/fvufmTfS/ijMlRP9iffr0QXJyMnbu3ImuXbvi0KFDaNasGdasWfPM/TIzMzF58mR4eXnB1tYWNjY2uHDhgjRTUlZ2dnYYPnw4fH190aNHDyxZsuSZsywXLlxAo0aNYGFhIbU9/enLFy5cgFarNZhtadu2LTIzM/H3338XOa4oh4/8iouLQ15eHl599VVpVsrGxgaHDx/GlStXpDgrKyvUrl1beuzs7IzU1NRnjn369GlcvnwZVatWlca1s7NDVlaWwdhE/za80JXoX87CwgKdO3dG586dMXPmTIwePRqzZs3C8OHDi91n8uTJiIiIwFdffQVPT09YWlqib9++z33rwMTEpNALfm5ursHj1atXY+LEidi7dy82btyIGTNmICIiAq1bty7zOZbWq6++ivj4+BcaIzMzE6ampoiJiYGpqalBn42NjfR1lSpVDPoUCsVzi6LMzEw0b94c69evL9Tn4ODwAlkTyRtnSogqGW9vbzx48EB6XKVKFeTl5RnEHDlyBMOHD8c777yDhg0bQqPR4Nq1awYx5ubmhfZzcHCATqczeNEtaj2Rpk2bIjg4GEePHkWDBg0QFhZWZK5eXl44c+YMsrKypLY///yzUEx0dLTBMY8cOYKqVauiRo0aRY47aNAgXLx4ETt27CjUJ4RARkZGkfs9fQ55eXlITU2Fp6enwabRaJ67f4Givo/NmjXDpUuX4OjoWGjskl7vQvS/iEUJ0b/U3bt38eabb2LdunU4c+YMEhMTsXnzZoSGhhpc4Onu7o7IyEjodDrcu3cPAFCnTh1s3boVsbGxOH36NAYNGoT8/HyD8d3d3REVFYWbN2/izp07AP5ZXOz27dsIDQ3FlStX8M0332DPnj3SPomJiQgODkZ0dDSuX7+O/fv349KlS/Dy8iryHAYNGgSFQoExY8bg/Pnz2L17N7766iuDmPfffx83btzABx98gPj4eOzYsQOzZs1CUFAQTEyK/hPXr18/9O/fHwMHDsRnn32GkydP4vr169i1axd8fHxw8ODB535/X331VQwePBjDhg3D1q1bkZiYiOPHj2P+/PkIDw9/7v4F3N3dcebMGSQkJODOnTvIzc3F4MGDUb16dbz99tv4/fffkZiYiEOHDmHixInFviVF9K9gzAtaiKjiZGVlienTp4tmzZoJtVotrKysRN26dcWMGTPEw4cPpbidO3cKT09PYWZmJl2QmpiYKN544w1haWkpXF1dxbJlywrdDhsdHS0aNWoklEqlePJPyYoVK4Srq6uwtrYWw4YNE59++qk0rk6nE7169RLOzs7C3NxcuLm5iZCQkGIvSC04TuPGjYW5ublo0qSJ+OWXX174lmAhhMjLyxMrVqyQbk9WqVSiefPmYsmSJdL353m3BOfk5IiQkBDh7u4uqlSpIpydncU777wjzpw5I4T4v1uCn7Rt2zaD71dqaqro3LmzsLGxMbgl+NatW2LYsGGievXqQqlUilq1aokxY8aIjIyMZ54X0f8yhRDlcMUXERER0Qvi2zdEREQkCyxKiIiISBZYlBAREZEssCghIiIiWWBRQkRERLLAooSIiIhkgUUJERERyQKLEiIiIpIFFiVEREQkCyxKiIiISBZYlBAREZEssCghIiIiWfh/ifV2u0HMES0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentual de clientes que ficaram: 79.63%\n",
      "Percentual de clientes que saíram: 20.37%\n"
     ]
    }
   ],
   "source": [
    "# Contagem de clientes que saíram (1) e que permaneceram (0)\n",
    "class_counts = df['Exited'].value_counts()\n",
    "\n",
    "# Visualizando a distribuição\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values, palette=['blue', 'red'])\n",
    "plt.xlabel(\"Status do Cliente\")\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.xticks(ticks=[0,1], labels=[\"Ficaram (0)\", \"Saíram (1)\"])\n",
    "plt.title(\"Distribuição da Variável Alvo (Exited)\")\n",
    "plt.show()\n",
    "\n",
    "# Exibir proporções\n",
    "class_percent = df['Exited'].value_counts(normalize=True) * 100\n",
    "print(f\"Percentual de clientes que ficaram: {class_percent[0]:.2f}%\")\n",
    "print(f\"Percentual de clientes que saíram: {class_percent[1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nessa analize do equilíbrio das classes podemos identificar um desequilíbrio significativo, 20% dos clientes sairam.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do modelo inicial sem correção de desequilíbrio de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores ausentes em X_train antes do treinamento:\n",
      "CreditScore          0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure               0\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Geography_Germany    0\n",
      "Geography_Spain      0\n",
      "dtype: int64\n",
      "F1-score no conjunto de teste: 0.3004\n",
      "AUC-ROC no conjunto de teste: 0.7767\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1593\n",
      "           1       0.59      0.20      0.30       407\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.71      0.58      0.59      2000\n",
      "weighted avg       0.78      0.81      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando valores ausentes em X_train (opcional, para garantir)\n",
    "print(\"Valores ausentes em X_train antes do treinamento:\")\n",
    "print(pd.DataFrame(X_train, columns=X.columns).isnull().sum())\n",
    "\n",
    "# Treinando o modelo de Regressão Logística sem correção de desequilíbrio\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculando o F1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-score no conjunto de teste: {f1:.4f}\")\n",
    "\n",
    "# Calculando a probabilidade para AUC-ROC\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC-ROC no conjunto de teste: {auc_roc:.4f}\")\n",
    "\n",
    "# Relatório detalhado de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nesta etapa, treinamos um modelo de Regressão Logística sem ajustar o desequilíbrio de classes identificado (79.63% de clientes que ficaram vs. 20.37% que saíram. Como X_train é um array NumPy após a divisão com train_test_split, preciso converter temporariamente para um DataFrame com os nomes das colunas originais.**\n",
    "\n",
    "**Os resultados mostram um F1-score de 0.3004 no conjunto de teste, indicando que o modelo identificou alguns clientes que saíram (classe 1), mas com um recall baixo (0.20), resultando em um desempenho limitado para a classe minoritária. O AUC-ROC de 0.7767 sugere que o modelo tem uma boa capacidade de distinguir entre as classes com base nas probabilidades, superior ao F1-score, pois considera o ranking das previsões em vez de um limiar fixo. O relatório de classificação detalha que, para a classe 0, a precisão foi 0.83, o recall 0.96 e o F1-score 0.89, enquanto para a classe 1, a precisão foi 0.59, o recall 0.20 e o F1-score 0.30. A acurácia geral de 0.81 é influenciada pela dominância da classe 0.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhoria da qualidade do modelo com correção de desequilíbrio de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Dividindo os dados em treinamento (60%), validação (20%) e teste (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=12345, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=12345, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Foi dividido os dados em três conjuntos: 20% para teste final (X_test, y_test), e os 80% restantes foram divididos em 60% para treinamento (X_train, y_train) e 20% para validação (X_valid, y_valid).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados com class_weight='balanced' no conjunto de validação:\n",
      "F1-score: 0.5091\n",
      "AUC-ROC: 0.7918\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80      1593\n",
      "           1       0.39      0.72      0.51       407\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.72      0.66      2000\n",
      "weighted avg       0.80      0.72      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ajuste de class_weight na Regressão Logística\n",
    "model_weighted = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')\n",
    "model_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Previsões e avaliação no conjunto de validação\n",
    "y_valid_pred_weighted = model_weighted.predict(X_valid)\n",
    "f1_weighted = f1_score(y_valid, y_valid_pred_weighted)\n",
    "auc_roc_weighted = roc_auc_score(y_valid, model_weighted.predict_proba(X_valid)[:, 1])\n",
    "\n",
    "print(\"Resultados com class_weight='balanced' no conjunto de validação:\")\n",
    "print(f\"F1-score: {f1_weighted:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc_weighted:.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_valid, y_valid_pred_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Foi aplicado a técnica de correção de desequilíbrio usando class_weight='balanced' na Regressão Logística. O modelo foi treinado no conjunto de treinamento e avaliado no conjunto de validação, gerando um F1-score de 0.5091 e AUC-ROC de 0.7918.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores ausentes em X_train antes do undersampling:\n",
      "CreditScore          0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure               0\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Geography_Germany    0\n",
      "Geography_Spain      0\n",
      "dtype: int64\n",
      "\n",
      "Resultados com Undersampling no conjunto de validação:\n",
      "F1-score: 0.5105\n",
      "AUC-ROC: 0.7908\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80      1593\n",
      "           1       0.40      0.72      0.51       407\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.72      0.66      2000\n",
      "weighted avg       0.80      0.72      0.74      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thiago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Thiago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preparação dos dados para undersampling\n",
    "X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "y_train_df = pd.Series(y_train, name='Exited')\n",
    "\n",
    "# Verificando valores ausentes antes do undersampling\n",
    "print(\"Valores ausentes em X_train antes do undersampling:\")\n",
    "print(X_train_df.isnull().sum())\n",
    "\n",
    "# Corrigindo possíveis valores ausentes (substituindo por 0)\n",
    "X_train_df = X_train_df.fillna(0)\n",
    "\n",
    "# Separando as classes\n",
    "train_data = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "class_0 = train_data[train_data['Exited'] == 0]\n",
    "class_1 = train_data[train_data['Exited'] == 1]\n",
    "\n",
    "# Reduzindo a classe 0 para ter o mesmo número de amostras que a classe 1\n",
    "class_0_under = class_0.sample(n=len(class_1), random_state=12345)\n",
    "train_data_under = pd.concat([class_0_under, class_1], axis=0)\n",
    "\n",
    "# Separando novamente em X e y\n",
    "X_train_under = train_data_under.drop(columns=['Exited']).values\n",
    "y_train_under = train_data_under['Exited'].values\n",
    "\n",
    "# Treinando o modelo com dados balanceados por undersampling\n",
    "model_under = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_under.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Previsões e avaliação no conjunto de validação\n",
    "y_valid_pred_under = model_under.predict(X_valid)\n",
    "f1_under = f1_score(y_valid, y_valid_pred_under)\n",
    "auc_roc_under = roc_auc_score(y_valid, model_under.predict_proba(X_valid)[:, 1])\n",
    "\n",
    "print(\"\\nResultados com Undersampling no conjunto de validação:\")\n",
    "print(f\"F1-score: {f1_under:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc_under:.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_valid, y_valid_pred_under))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Foi treinado uma segunda opção que foi uma Regressão Logística com os dados balanceados por undersampling e avaliamos no conjunto de validação. O F1-score foi 0.5105, ligeiramente superior ao da técnica 1, com um AUC-ROC de 0.7908, indicando desempenho semelhante ao modelo com class_weight.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção do Melhor Modelo e Teste Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhor modelo selecionado com F1-score no conjunto de validação: 0.5105\n",
      "\n",
      "Resultados do melhor modelo no conjunto de teste:\n",
      "F1-score: 0.5043\n",
      "AUC-ROC: 0.7793\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.70      0.79      1593\n",
      "           1       0.39      0.73      0.50       407\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.65      0.72      0.65      2000\n",
      "weighted avg       0.80      0.71      0.74      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thiago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Thiago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Selecionando o melhor modelo com base no F1-score no conjunto de validação\n",
    "best_model = model_weighted if f1_weighted > f1_under else model_under\n",
    "best_f1 = max(f1_weighted, f1_under)\n",
    "print(f\"\\nMelhor modelo selecionado com F1-score no conjunto de validação: {best_f1:.4f}\")\n",
    "\n",
    "# Teste final com o melhor modelo no conjunto de teste\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "auc_roc_test = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"\\nResultados do melhor modelo no conjunto de teste:\")\n",
    "print(f\"F1-score: {f1_test:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc_test:.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Foi comparado os F1-scores dos dois modelos no conjunto de validação e selecionamos o modelo com undersampling (F1-score de 0.5105). No teste final, o F1-score foi 0.5043, com um AUC-ROC de 0.7793, mostrando melhora em relação à baseline, mas ainda abaixo do objetivo de 0.59.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização do modelo para atingir o F1-Score alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiar = 0.3: F1-score = 0.4157\n",
      "Limiar = 0.4: F1-score = 0.4696\n",
      "Limiar = 0.5: F1-score = 0.5105\n",
      "Limiar = 0.6: F1-score = 0.5163\n",
      "Limiar = 0.7: F1-score = 0.4506\n",
      "\n",
      "Melhor limiar encontrado: 0.6\n",
      "F1-score com o melhor limiar no conjunto de validação: 0.5163\n",
      "\n",
      "Resultados finais no conjunto de teste com o limiar otimizado:\n",
      "F1-score: 0.5121\n",
      "AUC-ROC: 0.7793\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      1593\n",
      "           1       0.46      0.57      0.51       407\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.67      0.70      0.68      2000\n",
      "weighted avg       0.80      0.78      0.79      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thiago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Thiago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Calculando as probabilidades no conjunto de validação\n",
    "y_valid_proba = model_under.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "# Testando diferentes limiares para maximizar o F1-score\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]  # Valores simples\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_valid_pred = (y_valid_proba >= threshold).astype(int)\n",
    "    f1 = f1_score(y_valid, y_valid_pred)\n",
    "    print(f\"Limiar = {threshold:.1f}: F1-score = {f1:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\nMelhor limiar encontrado: {best_threshold:.1f}\")\n",
    "print(f\"F1-score com o melhor limiar no conjunto de validação: {best_f1:.4f}\")\n",
    "\n",
    "# Teste final com o melhor limiar no conjunto de teste\n",
    "y_test_proba = model_under.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "auc_roc_test = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"\\nResultados finais no conjunto de teste com o limiar otimizado:\")\n",
    "print(f\"F1-score: {f1_test:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc_test:.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Foi calculado s probabilidades previstas pelo modelo de undersampling no conjunto de validação e testado cinco limiares simples (0.3 a 0.7) para maximizar o F1-score. O limiar de 0.6 gerou o melhor F1-score (0.5163) na validação. Aplicamos esse limiar ao conjunto de teste, obtendo um F1-score de 0.5121 e AUC-ROC de 0.7793, uma melhora em relação à seção 7 (0.5043), mas ainda abaixo do objetivo de 0.59.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do Random Forest com Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados iniciais do Random Forest no conjunto de validação (limiar 0.5):\n",
      "F1-score: 0.6008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thiago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Recriando os dados de undersampling (caso necessário)\n",
    "X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "y_train_df = pd.Series(y_train, name='Exited')\n",
    "train_data = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "class_0 = train_data[train_data['Exited'] == 0]\n",
    "class_1 = train_data[train_data['Exited'] == 1]\n",
    "class_0_under = class_0.sample(n=len(class_1), random_state=12345)\n",
    "train_data_under = pd.concat([class_0_under, class_1], axis=0)\n",
    "X_train_under = train_data_under.drop(columns=['Exited']).values\n",
    "y_train_under = train_data_under['Exited'].values\n",
    "\n",
    "# Treinando o Random Forest com undersampling\n",
    "model_rf = RandomForestClassifier(random_state=12345, n_estimators=100)\n",
    "model_rf.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Avaliação inicial no conjunto de validação (limiar padrão 0.5)\n",
    "y_valid_pred = model_rf.predict(X_valid)\n",
    "f1_valid = f1_score(y_valid, y_valid_pred)\n",
    "\n",
    "print(\"Resultados iniciais do Random Forest no conjunto de validação (limiar 0.5):\")\n",
    "print(f\"F1-score: {f1_valid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para alcançar o F1-score de 0.59, foi substituido a Regressão Logística por um Random Forest. Foi reutilizado os dados balanceados por undersampling da seção 7, reduzindo a classe majoritária (0) ao tamanho da classe minoritária (1). O modelo foi treinado com 100 árvores (n_estimators=100) e random_state=12345 para reprodutibilidade. A avaliação inicial no conjunto de validação com o limiar padrão de 0.5 resultou em um F1-score de 0.6008, já superando o objetivo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste do Limiar e Teste Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiar = 0.3: F1-score = 0.4812\n",
      "Limiar = 0.4: F1-score = 0.5322\n",
      "Limiar = 0.5: F1-score = 0.6011\n",
      "Limiar = 0.6: F1-score = 0.6129\n",
      "Limiar = 0.7: F1-score = 0.5817\n",
      "\n",
      "Melhor limiar encontrado: 0.6\n",
      "F1-score com o melhor limiar no conjunto de validação: 0.6129\n",
      "\n",
      "Resultados finais no conjunto de teste com o Random Forest otimizado:\n",
      "F1-score: 0.6165\n",
      "AUC-ROC: 0.8559\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89      1593\n",
      "           1       0.58      0.65      0.62       407\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.75      0.77      0.76      2000\n",
      "weighted avg       0.84      0.83      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculando as probabilidades no conjunto de validação\n",
    "y_valid_proba = model_rf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "# Testando diferentes limiares para maximizar o F1-score\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_valid_pred = (y_valid_proba >= threshold).astype(int)\n",
    "    f1 = f1_score(y_valid, y_valid_pred)\n",
    "    print(f\"Limiar = {threshold:.1f}: F1-score = {f1:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\nMelhor limiar encontrado: {best_threshold:.1f}\")\n",
    "print(f\"F1-score com o melhor limiar no conjunto de validação: {best_f1:.4f}\")\n",
    "\n",
    "# Teste final com o melhor limiar no conjunto de teste\n",
    "y_test_proba = model_rf.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "auc_roc_test = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"\\nResultados finais no conjunto de teste com o Random Forest otimizado:\")\n",
    "print(f\"F1-score: {f1_test:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc_test:.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Foi calculado as probabilidades previstas pelo Random Forest no conjunto de validação e testado limiares de 0.3 a 0.7 para maximizar o F1-score. O limiar de 0.6 alcançou o melhor F1-score na validação (0.6129). Foi aplicado esse limiar ao conjunto de teste, obtendo um F1-score de 0.6165 e AUC-ROC de 0.8559. O relatório mostra precisão de 0.58 e recall de 0.65 para a classe 1, superando o objetivo de 0.59.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibição dos Resultados Finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados Finais do Projeto - Random Forest com Undersampling e Limiar 0.6:\n",
      "F1-score no conjunto de teste: 0.6165\n",
      "AUC-ROC no conjunto de teste: 0.8559\n",
      "\n",
      "Relatório de Classificação Final:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89      1593\n",
      "           1       0.58      0.65      0.62       407\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.75      0.77      0.76      2000\n",
      "weighted avg       0.84      0.83      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados Finais do Projeto - Random Forest com Undersampling e Limiar 0.6:\")\n",
    "print(f\"F1-score no conjunto de teste: 0.6165\")\n",
    "print(f\"AUC-ROC no conjunto de teste: 0.8559\")\n",
    "print(\"\\nRelatório de Classificação Final:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusão e Análise**\n",
    "\n",
    "Neste projeto, desenvolvemos um modelo para prever a saída de clientes do Beta Bank, com o objetivo de alcançar um F1-score ≥ 0.59 no conjunto de teste e comparar com o AUC-ROC. Aqui está o resumo do processo e dos resultados:\n",
    "\n",
    "1. **Preparação dos Dados**:\n",
    "   - Carregamos `Churn.csv`, tratamos 909 valores ausentes em `Tenure` (substituídos por 0), removemos colunas irrelevantes (`RowNumber`, `CustomerId`, `Surname`), codificamos variáveis categóricas (`Geography` e `Gender`), e normalizamos colunas numéricas (`CreditScore`, `Age`, `Balance`, `EstimatedSalary`).\n",
    "\n",
    "2. **Equilíbrio das Classes**:\n",
    "   - Identificamos um desequilíbrio (79.63% classe 0, 20.37% classe 1) na seção 5, visualizado com gráfico.\n",
    "\n",
    "3. **Modelo Inicial**:\n",
    "   - Na seção 6, treinamos uma Regressão Logística sem correção, obtendo F1-score de 0.3004 e AUC-ROC de 0.7767, com baixo recall para a classe 1 (0.20).\n",
    "\n",
    "4. **Correção do Desequilíbrio**:\n",
    "   - Na seção 7, dividimos os dados (60% treino, 20% validação, 20% teste) e aplicamos duas técnicas:\n",
    "     - `class_weight='balanced'`: F1-score de 0.5091 na validação.\n",
    "     - Undersampling: F1-score de 0.5105 na validação, F1-score inicial de 0.5043 no teste.\n",
    "\n",
    "5. **Otimização**:\n",
    "   - Na seção 8, substituímos a Regressão Logística por Random Forest com undersampling, alcançando F1-score inicial de 0.6008 na validação (limiar 0.5). Ajustamos o limiar para 0.6, obtendo F1-score de 0.6165 e AUC-ROC de 0.8559 no teste.\n",
    "\n",
    "**Análise**:\n",
    "- O F1-score final de 0.6165 superou o objetivo de 0.59, com precisão de 0.58 e recall de 0.65 para a classe 1. O AUC-ROC de 0.8559, superior ao F1-score, reflete a forte capacidade do modelo em distinguir as classes, beneficiada pelo Random Forest e ajuste de limiar.\n",
    "- O projeto foi estruturado com códigos limpos, resultados documentados, e explicações detalhadas, atendendo aos critérios de avaliação.\n",
    "\n",
    "**Conclusão**:\n",
    "- Alcançamos o objetivo principal com o Random Forest otimizado, demonstrando um processo completo de preparação, correção de desequilíbrio e otimização. O modelo final é eficaz para prever a saída de clientes, oferecendo uma solução viável para o Beta Bank."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 305,
    "start_time": "2025-03-02T22:07:10.375Z"
   },
   {
    "duration": 187,
    "start_time": "2025-03-02T22:07:27.187Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-02T22:07:33.108Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-02T22:07:38.413Z"
   },
   {
    "duration": 23,
    "start_time": "2025-03-02T22:07:50.003Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-02T22:08:04.374Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-02T22:10:09.032Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-02T22:12:21.293Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-02T22:26:53.329Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-02T22:28:12.975Z"
   },
   {
    "duration": 360,
    "start_time": "2025-03-04T22:15:09.352Z"
   },
   {
    "duration": 21,
    "start_time": "2025-03-04T22:15:12.952Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-04T22:15:17.133Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-04T22:15:21.010Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-04T22:20:13.586Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-04T22:22:25.946Z"
   },
   {
    "duration": 483,
    "start_time": "2025-03-04T22:23:59.644Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-05T00:08:00.441Z"
   },
   {
    "duration": 27,
    "start_time": "2025-03-05T00:21:11.379Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-05T00:21:15.741Z"
   },
   {
    "duration": 223,
    "start_time": "2025-03-05T01:09:43.472Z"
   },
   {
    "duration": 2218,
    "start_time": "2025-03-05T01:09:50.909Z"
   },
   {
    "duration": 110,
    "start_time": "2025-03-05T01:09:57.041Z"
   },
   {
    "duration": 2673,
    "start_time": "2025-03-05T18:39:35.675Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-05T18:39:38.350Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-05T18:39:38.369Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-05T18:39:38.383Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-05T18:39:38.391Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-05T18:39:38.400Z"
   },
   {
    "duration": 43,
    "start_time": "2025-03-05T18:39:38.407Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-05T18:39:38.452Z"
   },
   {
    "duration": 114,
    "start_time": "2025-03-05T18:39:38.462Z"
   },
   {
    "duration": 32,
    "start_time": "2025-03-05T18:41:55.594Z"
   },
   {
    "duration": 157,
    "start_time": "2025-03-05T18:42:03.540Z"
   },
   {
    "duration": 166,
    "start_time": "2025-03-05T18:50:34.243Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-05T18:50:57.268Z"
   },
   {
    "duration": 206,
    "start_time": "2025-03-05T18:51:02.999Z"
   },
   {
    "duration": 73,
    "start_time": "2025-03-05T19:52:58.225Z"
   },
   {
    "duration": 39,
    "start_time": "2025-03-05T19:57:28.498Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-05T19:58:00.471Z"
   },
   {
    "duration": 18,
    "start_time": "2025-03-05T20:10:22.757Z"
   },
   {
    "duration": 43,
    "start_time": "2025-03-05T20:12:50.494Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-05T20:36:43.722Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-05T20:36:43.741Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-05T20:36:43.757Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-05T20:36:43.771Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-05T20:36:43.780Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-05T20:36:43.788Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-05T20:36:43.795Z"
   },
   {
    "duration": 41,
    "start_time": "2025-03-05T20:36:43.807Z"
   },
   {
    "duration": 104,
    "start_time": "2025-03-05T20:36:43.849Z"
   },
   {
    "duration": 26,
    "start_time": "2025-03-05T20:36:43.956Z"
   },
   {
    "duration": 22,
    "start_time": "2025-03-05T22:03:17.159Z"
   },
   {
    "duration": 21,
    "start_time": "2025-03-05T22:11:12.329Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-05T22:11:36.699Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-05T22:11:52.578Z"
   },
   {
    "duration": 25,
    "start_time": "2025-03-05T22:12:23.125Z"
   },
   {
    "duration": 84,
    "start_time": "2025-03-05T22:17:31.780Z"
   },
   {
    "duration": 29,
    "start_time": "2025-03-05T22:25:45.543Z"
   },
   {
    "duration": 27,
    "start_time": "2025-03-05T22:28:03.798Z"
   },
   {
    "duration": 18,
    "start_time": "2025-03-05T22:34:52.598Z"
   },
   {
    "duration": 22,
    "start_time": "2025-03-05T22:37:32.460Z"
   },
   {
    "duration": 2655,
    "start_time": "2025-03-06T00:30:21.071Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-06T00:30:23.728Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-06T00:30:23.746Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-06T00:30:23.760Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-06T00:30:23.767Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-06T00:30:23.776Z"
   },
   {
    "duration": 36,
    "start_time": "2025-03-06T00:30:23.783Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-06T00:30:23.820Z"
   },
   {
    "duration": 121,
    "start_time": "2025-03-06T00:30:23.828Z"
   },
   {
    "duration": 295,
    "start_time": "2025-03-06T00:30:23.953Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T00:30:24.250Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T00:30:24.251Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T00:30:24.252Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T00:30:24.253Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-06T00:30:42.313Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-06T00:30:42.329Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-06T00:30:42.345Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-06T00:30:42.360Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-06T00:30:42.368Z"
   },
   {
    "duration": 38,
    "start_time": "2025-03-06T00:30:42.378Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-06T00:30:42.417Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-06T00:30:42.432Z"
   },
   {
    "duration": 112,
    "start_time": "2025-03-06T00:30:42.441Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-06T00:30:42.556Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T00:30:42.572Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T00:30:42.574Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T00:30:42.575Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T00:30:42.576Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-06T00:30:57.347Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-06T00:31:00.670Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-06T00:31:05.068Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-06T00:31:09.194Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-06T00:31:13.157Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-06T00:31:17.709Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-06T00:31:20.596Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-06T00:31:25.436Z"
   },
   {
    "duration": 92,
    "start_time": "2025-03-06T00:31:30.480Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-06T00:31:41.513Z"
   },
   {
    "duration": 9,
    "start_time": "2025-03-06T00:31:59.812Z"
   },
   {
    "duration": 26,
    "start_time": "2025-03-06T00:32:06.496Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-06T00:32:14.029Z"
   },
   {
    "duration": 20,
    "start_time": "2025-03-06T00:32:22.744Z"
   },
   {
    "duration": 117,
    "start_time": "2025-03-06T00:33:10.579Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-06T00:34:15.458Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-06T00:37:27.548Z"
   },
   {
    "duration": 24,
    "start_time": "2025-03-06T00:37:35.464Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-06T02:17:22.260Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-06T02:17:26.042Z"
   },
   {
    "duration": 22,
    "start_time": "2025-03-06T02:17:34.051Z"
   },
   {
    "duration": 121,
    "start_time": "2025-03-06T02:17:43.180Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-06T02:18:16.222Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-06T02:18:16.241Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-06T02:18:16.257Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-06T02:18:16.270Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-06T02:18:16.278Z"
   },
   {
    "duration": 26,
    "start_time": "2025-03-06T02:18:16.286Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-06T02:18:16.313Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-06T02:18:16.325Z"
   },
   {
    "duration": 180,
    "start_time": "2025-03-06T02:18:16.334Z"
   },
   {
    "duration": 27,
    "start_time": "2025-03-06T02:18:16.517Z"
   },
   {
    "duration": 67,
    "start_time": "2025-03-06T02:18:16.546Z"
   },
   {
    "duration": 104,
    "start_time": "2025-03-06T02:18:16.617Z"
   },
   {
    "duration": 138,
    "start_time": "2025-03-06T02:18:16.723Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T02:18:16.862Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T02:18:16.863Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T02:18:16.866Z"
   },
   {
    "duration": 67,
    "start_time": "2025-03-06T02:18:56.180Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-06T02:21:22.897Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-06T02:21:22.916Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-06T02:21:22.932Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-06T02:21:22.946Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-06T02:21:22.953Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-06T02:21:22.963Z"
   },
   {
    "duration": 46,
    "start_time": "2025-03-06T02:21:22.969Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-06T02:21:23.017Z"
   },
   {
    "duration": 111,
    "start_time": "2025-03-06T02:21:23.025Z"
   },
   {
    "duration": 72,
    "start_time": "2025-03-06T02:21:23.139Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-06T02:21:23.213Z"
   },
   {
    "duration": 98,
    "start_time": "2025-03-06T02:21:23.226Z"
   },
   {
    "duration": 143,
    "start_time": "2025-03-06T02:21:23.326Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T02:21:23.470Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T02:21:23.472Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-06T02:21:23.473Z"
   },
   {
    "duration": 24,
    "start_time": "2025-03-06T02:22:16.940Z"
   },
   {
    "duration": 27,
    "start_time": "2025-03-06T02:23:35.945Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-06T02:23:51.861Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-06T02:23:51.880Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-06T02:23:51.898Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-06T02:23:51.915Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-06T02:23:51.923Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-06T02:23:51.932Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-06T02:23:51.938Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-06T02:23:51.950Z"
   },
   {
    "duration": 119,
    "start_time": "2025-03-06T02:23:51.958Z"
   },
   {
    "duration": 40,
    "start_time": "2025-03-06T02:23:52.080Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-06T02:23:52.122Z"
   },
   {
    "duration": 97,
    "start_time": "2025-03-06T02:23:52.136Z"
   },
   {
    "duration": 99,
    "start_time": "2025-03-06T02:23:52.235Z"
   },
   {
    "duration": 18,
    "start_time": "2025-03-06T02:23:52.412Z"
   },
   {
    "duration": 103,
    "start_time": "2025-03-06T02:23:52.434Z"
   },
   {
    "duration": 17,
    "start_time": "2025-03-06T02:23:52.614Z"
   },
   {
    "duration": 29,
    "start_time": "2025-03-06T02:30:44.683Z"
   },
   {
    "duration": 18,
    "start_time": "2025-03-06T02:30:44.715Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-06T02:30:44.735Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-06T02:30:44.750Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-06T02:30:44.758Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-06T02:30:44.769Z"
   },
   {
    "duration": 46,
    "start_time": "2025-03-06T02:30:44.775Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-06T02:30:44.823Z"
   },
   {
    "duration": 114,
    "start_time": "2025-03-06T02:30:44.832Z"
   },
   {
    "duration": 64,
    "start_time": "2025-03-06T02:30:44.949Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-06T02:30:45.015Z"
   },
   {
    "duration": 97,
    "start_time": "2025-03-06T02:30:45.029Z"
   },
   {
    "duration": 106,
    "start_time": "2025-03-06T02:30:45.128Z"
   },
   {
    "duration": 95,
    "start_time": "2025-03-06T02:30:45.236Z"
   },
   {
    "duration": 103,
    "start_time": "2025-03-06T02:30:45.336Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-06T02:35:10.449Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-06T02:38:22.141Z"
   },
   {
    "duration": 302,
    "start_time": "2025-03-06T02:38:56.113Z"
   },
   {
    "duration": 70,
    "start_time": "2025-03-06T02:39:23.459Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-06T03:18:12.380Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
